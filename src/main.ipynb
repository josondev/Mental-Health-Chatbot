{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae9872a",
   "metadata": {},
   "source": [
    "this is for developers who want to take the individual parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing all the imports here \n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone,ServerlessSpec,PineconeApiException\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.chains import create_history_aware_retriever,create_retrieval_chain\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41545c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the environment variables from the .env file\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"]=os.getenv(\"PINECONE_API_KEY\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ad26927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the pinecone parameters\n",
    "pc=Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "spec=ServerlessSpec(cloud=os.getenv(\"PINECONE_CLOUD\"), region=os.getenv(\"PINECONE_REGION\"))\n",
    "\n",
    "#initialising the embedding model \n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1ac85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinecone index name and if it is not present it will be handled by exception handling\n",
    "index_name=\"medical-chatbot\"\n",
    "try:\n",
    "    result=pc.Index(index_name).describe_index_stats()\n",
    "except PineconeApiException as e:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embeddings.dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=spec\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "841c7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pinecone vector store initialisation for retrieval chain so that this can be chained with the chat model \n",
    "vectorstore=PineconeVectorStore.from_existing_index(index_name=index_name,embedding=embeddings)\n",
    "base_retriever=vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "##initialising the llm for the chat model\n",
    "llm=ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-001\",temperature=0.1,\n",
    "    max_tokens=1024,\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    streaming=True  #necessary for streaming purposes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64cd05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for the main RAG part this is exclusively for the system part \n",
    "\n",
    "##This is a crucial component in building a conversational RAG (Retrieval Augmented Generation) system, as it allows the chatbot to understand follow-up questions \n",
    "# that refer to earlier parts of the conversation.\n",
    "\n",
    "#1)# Prompt to rephrase query based on chat history\n",
    "\n",
    "#Purpose: This string is a system message that defines the task for \n",
    "#  Large Language Model (LLM). It instructs the LLM on how to behave when given a chat history and a new user question.\n",
    "\n",
    "contextualize_question_system_prompt=(\n",
    "    \"Given a chat history and the latest user question\"\n",
    "    \"which might reference context in the chat history,\"\n",
    "    \"formulate a standalone question which can be understood\"\n",
    "    \"without the chat history. Do NOT answer the question,\"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "#2)# Prompt to answer the question based on the retrieved context\n",
    "\n",
    "# Purpose: This creates a structured prompt template that will be fed to the LLM. LangChain's ChatPromptTemplate is used to assemble a sequence of messages.\n",
    "contexualised_q_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_question_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever=create_history_aware_retriever(\n",
    "    llm=llm,retriever=base_retriever,\n",
    "    prompt=contexualised_q_prompt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9076d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This chain generates answers from retrieved documents and \n",
    "# incorporates chat history for conversational context.\n",
    "\n",
    "system_prompt=(\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. And DON'T answer questions outside mental health domain,\"\n",
    "    \"If you don't know the answer, say that you \"\n",
    "    \"don't know.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "qa_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a09f10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final touch and chat history \n",
    "rag_chain=create_retrieval_chain(\n",
    "    retriever=history_aware_retriever,\n",
    "    combine_docs_chain=question_answer_chain,\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def ask_question_streamed(user_question, current_chat_history):\n",
    "    print(f\"\\nUser: {user_question}\")\n",
    "    print(\"AI: \", end=\"\")\n",
    "    \n",
    "    full_ai_response = \"\"\n",
    "    # Use .stream() to get chunks of the response\n",
    "    for chunk in rag_chain.stream({\n",
    "        \"input\": user_question,\n",
    "        \"chat_history\": current_chat_history,\n",
    "    }):\n",
    "        # The 'answer' key should contain the streamed tokens from the LLM\n",
    "        # Other keys like 'context' might appear once, not streamed per token.\n",
    "        if \"answer\" in chunk and chunk[\"answer\"] is not None:\n",
    "            print(chunk[\"answer\"], end=\"\", flush=True)\n",
    "            full_ai_response += chunk[\"answer\"]\n",
    "            \n",
    "    print() # Newline after the full streamed response\n",
    "    \n",
    "    # Update chat history\n",
    "    current_chat_history.append(HumanMessage(content=user_question))\n",
    "    current_chat_history.append(AIMessage(content=full_ai_response))\n",
    "    return full_ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2710f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: How do traumatic or negative childhood events affect mental health?\n",
      "AI: Traumatic or negative childhood events can affect mental health in several ways:\n",
      "\n",
      "*   **Anxiety and Depression:** They may increase the risk of developing anxiety and depression later in life.\n",
      "*   **Post-Traumatic Stress Disorder (PTSD):** They can lead to the development of PTSD, involving distressing memories of the event.\n",
      "*   **Self-Esteem Issues:** They may contribute to feelings of low self-worth and self-esteem.\n",
      "*   **Trust and Relationship Challenges:** They can lead to difficulties in forming and maintaining healthy relationships.\n",
      "*   **Coping Mechanisms:** Individuals might develop maladaptive coping mechanisms like substance abuse or self-harm.\n",
      "\n",
      "User: who is narendra modi?\n",
      "AI: I am designed to answer questions related to mental health. I don't have information on that topic.\n",
      "\n",
      "User: What are symptoms of panic attack vs. anxiety attack?\n",
      "AI: Panic Attack Symptoms:\n",
      "\n",
      "1.  Heart palpitations, pounding heart, or accelerated heart rate.2.  Sweating or trembling.\n",
      "3.  Shortness of breath or feeling smothered.\n",
      "4.  Feeling of choking or a lump in the throat.\n",
      "5.  Chest pain or discomfort.\n",
      "6.  Nausea or abdominal distress.\n",
      "7.  Dizziness, lightheadedness, or feeling faint.\n",
      "8.  Chills or hot flashes.\n",
      "9.  Numbness or tingling sensations.\n",
      "10. Fear of losing control or going crazy.\n",
      "11. Fear of dying.\n",
      "12. A sense of detachment from reality or oneself (depersonalization).\n",
      "13. A feeling of being detached from the surroundings (derealization).\n",
      "\n",
      "Anxiety Attack Symptoms:\n",
      "\n",
      "1.  Excessive worrying or fear about future events or situations.\n",
      "2.  Restlessness or feeling on edge.3.  Muscle tension or aches.\n",
      "4.  Difficulty concentrating or mind going blank.\n",
      "5.  Irritability.\n",
      "6.  Fatigue or feeling easily fatigued.\n",
      "7.  Sleep disturbances, such as difficulty falling asleep or staying asleep.\n",
      "8.  Avoidance of triggers or situations that provoke anxiety.\n",
      "\n",
      "Panic attacks come on suddenly and involve intense and often overwhelming fear and are accompanied by very challenging physical symptoms. Anxiety attacks are different from panic attacks in terms of intensity and duration and are typically associated with prolonged feelings of worry, nervousness, and fear.\n"
     ]
    }
   ],
   "source": [
    "# Samples\n",
    "user_question_1 = \"How do traumatic or negative childhood events affect mental health?\" # Example from your image [1]\n",
    "ai_response_1 = ask_question_streamed(user_question_1, chat_history)\n",
    "\n",
    "user_question_2=\"who is narendra modi?\"\n",
    "ai_response_2 = ask_question_streamed(user_question_2, chat_history)\n",
    "\n",
    "user_question_3 = \"What are symptoms of panic attack vs. anxiety attack?\" # Example from your image [1]\n",
    "ai_response_3 = ask_question_streamed(user_question_3, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7601e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "while(flag):\n",
    "    user_input=input(\"Ask Any Question related to Mental Health:\")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
    "        print(\"Exiting the chat. Goodbye!\")\n",
    "        flag=False\n",
    "    else:\n",
    "        ai_response = ask_question_streamed(user_input, chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa52e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to delete the chat history \n",
    "\n",
    "for i in chat_history:\n",
    "    chat_history.remove(i)\n",
    "\n",
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmanus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
